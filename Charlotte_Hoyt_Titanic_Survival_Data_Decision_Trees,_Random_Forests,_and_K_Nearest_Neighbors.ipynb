{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CharlotteHoyt/KWK-Goldman-Sachs-ML-Titanic-Survival-Data-Decision-Trees-Random-Forests-and-K-Nearest-Neighbors/blob/main/Charlotte_Hoyt_Titanic_Survival_Data_Decision_Trees%2C_Random_Forests%2C_and_K_Nearest_Neighbors.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#KWK Machine Learning Challenge 2025\n",
        "##Titanic Survival Data - Decision Trees, Random Forests, and K-Nearest Neighbors\n",
        "\n",
        "This Notebook contains practice exercises for the Machine Learning Challenge guided curriculum lessons below:\n",
        "\n",
        "\n",
        "*   ML2.1 - Decision Trees\n",
        "*   ML2.2 - Random Forests\n",
        "*   ML3.1 - K-Nearest Neighbords\n",
        "\n",
        "TODO comments are added where you should fill in your own code."
      ],
      "metadata": {
        "id": "5BkN6FZ3getR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading and Cleaning Data\n",
        "\n",
        "Similarly to the previous notebook, we need to load and clean our dataset. This portion is done for you, since it is a repeat of concepts you've already learned. You will, however, need to replace the path to a file on your own Google Drive."
      ],
      "metadata": {
        "id": "7QU_84eGgwdr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "YFSlQKbw55VU",
        "outputId": "5db6902b-1c4e-4caa-afe1-a55ae9a60a2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   PassengerId  Survived  Pclass  \\\n",
              "0            1         0       3   \n",
              "1            2         1       1   \n",
              "2            3         1       3   \n",
              "3            4         1       1   \n",
              "4            5         0       3   \n",
              "\n",
              "                                                Name     Sex   Age  SibSp  \\\n",
              "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
              "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
              "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
              "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
              "4                           Allen, Mr. William Henry    male  35.0      0   \n",
              "\n",
              "   Parch            Ticket     Fare Cabin Embarked  \n",
              "0      0         A/5 21171   7.2500   NaN        S  \n",
              "1      0          PC 17599  71.2833   C85        C  \n",
              "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
              "3      0            113803  53.1000  C123        S  \n",
              "4      0            373450   8.0500   NaN        S  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e366923d-72b7-4a09-874e-d418985a8459\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Braund, Mr. Owen Harris</td>\n",
              "      <td>male</td>\n",
              "      <td>22.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>A/5 21171</td>\n",
              "      <td>7.2500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
              "      <td>female</td>\n",
              "      <td>38.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>PC 17599</td>\n",
              "      <td>71.2833</td>\n",
              "      <td>C85</td>\n",
              "      <td>C</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>Heikkinen, Miss. Laina</td>\n",
              "      <td>female</td>\n",
              "      <td>26.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>STON/O2. 3101282</td>\n",
              "      <td>7.9250</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
              "      <td>female</td>\n",
              "      <td>35.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>113803</td>\n",
              "      <td>53.1000</td>\n",
              "      <td>C123</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Allen, Mr. William Henry</td>\n",
              "      <td>male</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>373450</td>\n",
              "      <td>8.0500</td>\n",
              "      <td>NaN</td>\n",
              "      <td>S</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e366923d-72b7-4a09-874e-d418985a8459')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e366923d-72b7-4a09-874e-d418985a8459 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e366923d-72b7-4a09-874e-d418985a8459');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-dc0b9ad9-c870-4e2c-9ae8-109166b5c16e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dc0b9ad9-c870-4e2c-9ae8-109166b5c16e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-dc0b9ad9-c870-4e2c-9ae8-109166b5c16e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 891,\n  \"fields\": [\n    {\n      \"column\": \"PassengerId\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 257,\n        \"min\": 1,\n        \"max\": 891,\n        \"num_unique_values\": 891,\n        \"samples\": [\n          710,\n          440,\n          841\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Survived\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pclass\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 3,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          3,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 891,\n        \"samples\": [\n          \"Moubarek, Master. Halim Gonios (\\\"William George\\\")\",\n          \"Kvillner, Mr. Johan Henrik Johannesson\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Sex\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"female\",\n          \"male\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 14.526497332334044,\n        \"min\": 0.42,\n        \"max\": 80.0,\n        \"num_unique_values\": 88,\n        \"samples\": [\n          0.75,\n          22.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SibSp\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 0,\n        \"max\": 8,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Parch\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 6,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Ticket\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 681,\n        \"samples\": [\n          \"11774\",\n          \"248740\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fare\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 49.693428597180905,\n        \"min\": 0.0,\n        \"max\": 512.3292,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          11.2417,\n          51.8625\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cabin\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 147,\n        \"samples\": [\n          \"D45\",\n          \"B49\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Embarked\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"S\",\n          \"C\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# For more information on this, see this link: https://colab.research.google.com/notebooks/io.ipynb\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Basic import statements\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "#Replace the path below with the path to the file on your own Google Drive.\n",
        "df = pd.read_csv(\"/content/drive/My Drive/KWK_ML/titanic.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cleaning Data\n",
        "We need to do the following:\n",
        "\n",
        "*   Fill missing `Age` values with the median age.\n",
        "*   Fill missing `Embarked` values with the most common port (mode).\n",
        "*   Drop the `Cabin` column since most values are missing."
      ],
      "metadata": {
        "id": "thawIM4DhK6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing Age values with the median age\n",
        "median_age = df['Age'].median()\n",
        "df['Age'] = df['Age'].fillna(median_age)\n",
        "\n",
        "# Fill missing Embarked values with the most common port (mode)\n",
        "most_common_port = df['Embarked'].mode()[0]\n",
        "df['Embarked'] = df['Embarked'].fillna(most_common_port)\n",
        "\n",
        "# Drop the Cabin column since most values are missing\n",
        "df.drop(columns=['Cabin'], inplace=True)\n",
        "\n",
        "# re-run df.info() and see that the columns have updated as we expect.\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvh817nP6Ss-",
        "outputId": "7e0a6342-b129-4bd6-b80e-2c0c066d672c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 11 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          891 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Embarked     891 non-null    object \n",
            "dtypes: float64(2), int64(5), object(4)\n",
            "memory usage: 76.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's also add the `FamilySize` feature from the previous notebook."
      ],
      "metadata": {
        "id": "Gu6Bi_bQnBMX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add the columns `Parch` and `SibSp` and assign them to a\n",
        "# new column called `FamilySize`\n",
        "df['FamilySize'] = df['Parch'] + df['SibSp']"
      ],
      "metadata": {
        "id": "oCd1UyFRnAdR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML2.1.1 - Decision Trees\n",
        "\n",
        "In this section, we will create a decision tree. Before we do that, we need to engineer a new feature. The current `Sex` column stores passengers' sex as string values. Our decision tree model needs to take this column in as a numeric value. So, let's engineer a new feature, `Sex_Female`, where the value is `1` if the passenger is female and `0` if they are male."
      ],
      "metadata": {
        "id": "z4Doi_wIhdwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature engineering: Create a new column, Sex_Female, using the Sex column with 0 = male, 1 = female\n",
        "\n",
        "# Step one: print all unique values in the Sex column. This allows us to see whether\n",
        "# we need to do any string manipulation before we map the values\n",
        "print(set(df[\"Sex\"].values))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPDXW0aM6ee4",
        "outputId": "22d07ac4-c6f5-4ffb-939a-1dfba17cb432"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'female', 'male'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step two: create a new column with mapped values:\n",
        "# 0 for male, 1 for female\n",
        "\n",
        "# TODO: create the above-described column, named `Sex_Female`\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QOiAWzpkU4r",
        "outputId": "a8b3a988-7a0d-4314-b3db-85bcfd508899"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          891 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Embarked     891 non-null    object \n",
            " 11  FamilySize   891 non-null    int64  \n",
            "dtypes: float64(2), int64(6), object(4)\n",
            "memory usage: 83.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's also engineer another feature that one-hot encodes the `Embarked` column, since that column is similarly a text-based categorical variable."
      ],
      "metadata": {
        "id": "Ed7yXSvvlP40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step one: print all unique values in the Embarked column. This allows us to see whether\n",
        "# we need to do any string manipulation before we map the values\n",
        "print(set(df[\"Embarked\"].values))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knCgiMqKlPKP",
        "outputId": "72d1fc92-256a-47a1-a7cf-92995de3a943"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'S', 'C', 'Q'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step two: create the new columns using `get_dummies`\n",
        "\n",
        "# TODO: Get one hot encoding of column 'Embarked' and add to the existing df\n",
        "\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzhP9-GDljDn",
        "outputId": "b1ff1f0b-8025-4fff-c4d6-d369f337e98d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 12 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  891 non-null    int64  \n",
            " 1   Survived     891 non-null    int64  \n",
            " 2   Pclass       891 non-null    int64  \n",
            " 3   Name         891 non-null    object \n",
            " 4   Sex          891 non-null    object \n",
            " 5   Age          891 non-null    float64\n",
            " 6   SibSp        891 non-null    int64  \n",
            " 7   Parch        891 non-null    int64  \n",
            " 8   Ticket       891 non-null    object \n",
            " 9   Fare         891 non-null    float64\n",
            " 10  Embarked     891 non-null    object \n",
            " 11  FamilySize   891 non-null    int64  \n",
            "dtypes: float64(2), int64(6), object(4)\n",
            "memory usage: 83.7+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Decision Tree Model\n",
        "Now let's work on training the model, interpreting it, and evaluating it against testing data."
      ],
      "metadata": {
        "id": "b316nh8cng-h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step one: Gather the features we want to use in the model into X\n",
        "X = df[[\"Pclass\", \"Age\", \"Fare\", \"FamilySize\", \"Sex_Female\", \"Embarked_Q\", \"Embarked_S\"]]\n",
        "y = df[\"Survived\"]\n",
        "\n",
        "# Step two: Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Step three: Train the decision tree\n",
        "## TODO: step 3 as described.\n",
        "\n",
        "# Step five: Visualize the tree\n",
        "## TODO: step 5 as described.\n",
        "\n",
        "# Step six: List Ffature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    \"Feature\": X.columns,\n",
        "    \"Importance\": model.feature_importances_\n",
        "}).sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "print(\"\\nFeature Importance:\\n\", feature_importance)\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "# Step seven: Evaluate on the training set\n",
        "print(\"ACCURACY FOR THE TRAINING SET\")\n",
        "y_pred_train = model.predict(X_train)\n",
        "print(\"Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_train, y_pred_train))\n",
        "\n",
        "# Step seven: Evaluate on the test set\n",
        "print(\"ACCURACY FOR THE TEST SET\")\n",
        "y_pred_test = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_test))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "pvKF3u6hDvMx",
        "outputId": "68ecfb68-3267-46ad-a124-623cedf8fadb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "\"['Sex_Female', 'Embarked_Q', 'Embarked_S'] not in index\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3964454618.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Step one: Gather the features we want to use in the model into X\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Pclass\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Age\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Fare\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"FamilySize\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Sex_Female\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Embarked_Q\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Embarked_S\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Survived\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4106\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4107\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4108\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_indexer_strict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4110\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_get_indexer_strict\u001b[0;34m(self, key, axis_name)\u001b[0m\n\u001b[1;32m   6198\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6200\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_if_missing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6202\u001b[0m         \u001b[0mkeyarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36m_raise_if_missing\u001b[0;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[1;32m   6250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6251\u001b[0m             \u001b[0mnot_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmissing_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6252\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{not_found} not in index\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6254\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moverload\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: \"['Sex_Female', 'Embarked_Q', 'Embarked_S'] not in index\""
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluating the model\n",
        "Accuracy on the model above is:\n",
        "*    80.3% for the training set\n",
        "*    76.5% for the test set.\n",
        "\n",
        "This is pretty good! Let's see if we can push for better by tuning some of the parameters of the model, though. Specifically, we will:\n",
        "*  Increase `max_depth` from 2 to 4\n",
        "*  Set `min_samples_split` to 5\n",
        "* Set `min_samples_leaf` to 3\n",
        "\n"
      ],
      "metadata": {
        "id": "lt-WoV3Qovmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Steps 1 and 2 remain above; we'll use the same split of training and testing data.\n",
        "\n",
        "# Step three: Train the decision tree (this is where we change parameters)\n",
        "# TODO: step 3 as described.\n",
        "\n",
        "# Step five: Visualize the tree\n",
        "plt.figure(figsize=(32, 8))\n",
        "plot_tree(\n",
        "    model,\n",
        "    feature_names=X.columns,\n",
        "    class_names=[\"Did Not Survive\", \"Survived\"],\n",
        "    filled=True,\n",
        "    rounded=True\n",
        ")\n",
        "plt.show()\n",
        "\n",
        "# Step six: List Ffature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    \"Feature\": X.columns,\n",
        "    \"Importance\": model.feature_importances_\n",
        "}).sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "print(\"\\nFeature Importance:\\n\", feature_importance)\n",
        "\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "# Step seven: Evaluate on the training set\n",
        "print(\"ACCURACY FOR THE TRAINING SET\")\n",
        "y_pred_train = model.predict(X_train)\n",
        "print(\"Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_train, y_pred_train))\n",
        "\n",
        "# Step seven: Evaluate on the test set\n",
        "print(\"ACCURACY FOR THE TEST SET\")\n",
        "y_pred_test = model.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_test))"
      ],
      "metadata": {
        "id": "sTIdtjTHpERc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This seems a bit better! Accuracy for the new model above is:\n",
        "*    83.6% for the training set\n",
        "*    79.9% for the test set.\n",
        "\n",
        "This still represents an optimal balance between overfitting and not fitting strongly enough to the test data.\n"
      ],
      "metadata": {
        "id": "zHFkky9Sp6Zv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML.2.2.1 - Random Forests\n",
        "\n",
        "Next, let's level up to random forests: ensembles of many decision trees with their results combined through voting for which category (survived, or not survived) to predict for a given passenger."
      ],
      "metadata": {
        "id": "zUBjezmwyurn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1. Import libraries ---\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Step 2. Select features\n",
        "X = df[[\"Pclass\", \"Age\", \"Fare\", \"FamilySize\", \"Sex_Female\", \"Embarked_Q\", \"Embarked_S\"]]\n",
        "y = df[\"Survived\"]\n",
        "\n",
        "# Step 3. Split into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Step 4. Train a Random Forest model\n",
        "# TODO: Step 4 as described\n",
        "\n",
        "# Step 5: Evaluate on the training set\n",
        "print(\"\\nACCURACY FOR THE TRAINING SET\")\n",
        "y_pred_train = forest.predict(X_train)\n",
        "print(\"Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_train, y_pred_train))\n",
        "\n",
        "# Step 6: Evaluate on the test set\n",
        "print(\"\\nACCURACY FOR THE TEST SET\")\n",
        "y_pred_test = forest.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred_test))\n",
        "\n",
        "# Step 7. Visualize the confusion matrix\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Random Forest Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Step 8. Feature importance\n",
        "importance_df = pd.DataFrame({\n",
        "    \"Feature\": X.columns,\n",
        "    \"Importance\": forest.feature_importances_\n",
        "}).sort_values(by=\"Importance\", ascending=False)\n",
        "\n",
        "print(\"\\nFeature Importance:\\n\", importance_df)\n"
      ],
      "metadata": {
        "id": "7x-s8w7azByu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ðŸ’¬ Reflection: Decision Tree vs. Random Forest\n",
        "\n",
        "Now that you've trained both models, let's compare their results and think about what they tell us.\n",
        "\n",
        "| Model             | Train Accuracy | Test Accuracy | Notes                                  |\n",
        "| ----------------- | -------------- | ------------- | -------------------------------------- |\n",
        "| **Decision Tree** | 0.84           | 0.80          | Pretty good!  |\n",
        "| **Random Forest** | 0.86           | 0.82          | Slightly higher accuracy. |\n",
        "\n",
        "### 1. Generalization\n",
        "\n",
        "The Decision Tree learned slightly too specific patterns from the training data (0.84 â†’ 0.80).\n",
        "\n",
        "The Random Forest has a proportionally smaller gap (0.86 â†’ 0.82), meaning it generalizes better to unseen data.\n",
        "\n",
        "This is the core strength of ensemble learning: by combining many imperfect trees, the forest smooths out individual quirks and random noise.\n",
        "\n",
        "### 2. Precision, Recall, and Trade-offs\n",
        "| Metric                          | Decision Tree | Random Forest | Interpretation                                                           |\n",
        "| ------------------------------- | ------------- | ------------- | ------------------------------------------------------------------------ |\n",
        "| **Precision (Survived)**        | 0.84          | 0.85          | Both are good at correctly identifying survivors.                        |\n",
        "| **Recall (Survived)**           | 0.64          | 0.69          | The Random Forest catches a few more true survivors.                     |\n",
        "| **Precision (Did not survive)** | 0.78          | 0.81          | Both predict non-survivors accurately, but the forest slightly improves. |\n",
        "| **Recall (Did not survive)**    | 0.91          | 0.91          | Essentially the same: both correctly identify most non-survivors.       |\n",
        "\n",
        "Notice the small but consistent improvements across metrics.\n",
        "\n",
        "### 3. Questions for Reflection\n",
        "\n",
        "Type your answers below:\n",
        "\n",
        "**Why did the Random Forest achieve higher recall for survivors?**\n",
        "\n",
        "TODO: Answer here.\n",
        "\n",
        "**How does bootstrapping with replacement make the model more reliable?**\n",
        "\n",
        "TODO: Answer here.\n",
        "\n",
        "**What trade-off do we accept by using a Random Forest instead of one interpretable tree?**\n",
        "\n",
        "TODO: Answer here.\n",
        "\n",
        "**If your goal were to maximize survivor detection, what metric would you prioritize, precision or recall?  How might you adjust the model to improve it?**\n",
        "\n",
        "TODO: Answer here.\n"
      ],
      "metadata": {
        "id": "7eig2llY0FPu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML3.1.1 - K-Nearest Neighbors\n",
        "\n",
        "Now, let's train a KNN model on the dataset."
      ],
      "metadata": {
        "id": "fo86938S533I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Step 1. Normalize features (essential for KNN)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Step 2. Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_scaled, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Step 3. Train and evaluate a KNN model\n",
        "\n",
        "# TODO: step 3 as described.\n",
        "\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
        "\n",
        "# Step 4 Experiment: tune K\n",
        "k_values = range(1, 21)\n",
        "train_acc, test_acc = [], []\n",
        "\n",
        "for k in k_values:\n",
        "    # TODO: step 4: create a model, fit it, and evaluate it, appending its\n",
        "    # score to train_acc and test_acc\n",
        "\n",
        "plt.figure(figsize=(8,4))\n",
        "plt.plot(k_values, train_acc, label=\"Train Accuracy\")\n",
        "plt.plot(k_values, test_acc, label=\"Test Accuracy\")\n",
        "plt.xlabel(\"Number of Neighbors (K)\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.title(\"KNN Performance vs. K\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9dgeD_Ew6C7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ðŸ’¬ Reflection\n",
        "\n",
        "The KNN model achieved about 79% accuracy, which is solid but slightly lower than the random forest model. That makes sense: KNN is a simple, memory-based method; it relies entirely on proximity and can't easily capture more complex relationships in the data.\n",
        "\n",
        "Precision and recall are balanced across both classes, showing the model makes reasonable predictions for survivors and non-survivors alike. However, KNN tends to struggle with noisy or overlapping data (like age and fare combinations that don't cleanly separate survivors from non-survivors).\n",
        "\n",
        "Still, this performance demonstrates why KNN is a useful baseline model. It confirms that similarity-based reasoning can uncover real structure in the data, even without any training phase. And, it highlights how more sophisticated models, like Random Forests, build on that foundation to achieve stronger and more stable results.\n",
        "\n",
        "**How does changing the value of K affect both training and testing accuracy? What does this tell you about the balance between overfitting (too small K) and underfitting (too large K) in your model?**\n",
        "\n",
        "TODO: Answer here.\n",
        "\n",
        "**Where on your plot do you see the â€œsweet spotâ€ for K â€” the point of best generalization?\n",
        "How would you justify that choice based on what you observe in the training and testing curves?**\n",
        "\n",
        "TODO: Answer here.\n",
        "\n",
        "**How does your best KNN model compare to your Decision Tree and Random Forest results?\n",
        "What does that comparison suggest about when simple, instance-based models like KNN are effective versus when more structured models perform better?**\n",
        "\n",
        "TODO: Answer here."
      ],
      "metadata": {
        "id": "Yh8mIIuU6oVT"
      }
    }
  ]
}